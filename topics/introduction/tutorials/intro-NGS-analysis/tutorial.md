---
layout: tutorial_hands_on
topic_name: introduction
tutorial_name: intro_NGS_analysis
---

# Introduction
{:.no_toc}

In this tutorial you will learn the basics on how to work and analyse next-generation sequencing data. First we will deal with manipulation of fastq files, more precisely how to access the quality of the data and perform some quality treatments, and then we will deal with SAM/BAM files, learning how to map the data and visualize the results. 
The data we're using in this tutorial is from [The First Steps of Adaptation of Escherichia coli to the Gut Are Dominated by Soft Sweeps](http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004182) study and the genome utilized is from [here](https://www.ncbi.nlm.nih.gov/nuccore/556503834). 

> ### Agenda
>
> In this tutorial, we will deal with:
>
> 1. TOC
> {:toc}
>
{: .agenda}

# Fastq manipulation 

Most high-throughput sequencing machines output fastq files, the “de facto” current standard in HTS.
Fastq files are simply text files, where each block of information (a sequenced DNA fragment) in this
format is encoded as 4 lines. If you look at the first lines of a fastq file, you would see something like:

```
@HWI-M01876:76:000000000-AF16W:1:1101:10853:1000 1:N:0:CGTGACAGAT
NTGTACTTCATCCGAAACTCGTGCTCATCTCTGCTCAGATCGGAAGAGCACACGTCTGAACTCCAGTCACCGTGAT 
+ 
#8ABCFGGGFCEDCFGGGGGGGFFCGEFGGGGGGFGGGGGGGGDEFGGGGGGGGGGGGGGGGGFFFEGGGGGGGGF 
@HWI-M01876:76:000000000-AF16W:1:1101:16471:1000 1:N:0:CGTGAACTTG
NTTCCAGATATTCGATGCATGTGCCGCTCCTGTCGGAGATCGGAAGAGCACACGTCTGAACTCCAGTCACCGTGAT 
+ 
#8BCCGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGEGGGGFGGGGGGGGGGGGGGGGGGGGGGGGGG
```

We have two sequenced DNA fragments (or reads), where each read is represented by blocks of 4 lines,
with sequence and base quality information. Each block of information (4 lines) includes:

- 1.@ followed by read identifier
- 2.read sequence 
- 3.+ separator line
- 4.quality of each base based on ASCII score

Each base has a quality character associated with it, which represents how confidently the machine identified (called) the base. But how does this character translate into a probability of error?
The probability p of error per base is given as a **Phred score**, calculated from a value (Q) derived from the quality character associated to the base:

![](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a30ecef1f2739d87f5451d0a748d257e48a4bef "Source is wikipedia") 

Although there's theoretically no limit, Q usually goes up to around 40 in illumina machines.

To obtain this Q value from the character associated to the quality of the base, we have to know that each character (such as '#') has an ASCII decimal value associated (for example, '#' has a value of 35).
The Q value of a character is the decimal value corresponding to the entry of that character in the ASCII table, subtracted by 33. For example Q('#') = 35 – 33 = 2

> ### :pencil2: Hands-on: 
>
> 1. *__Interpret the quality of the bases__*: For the fastq file you just saw, analyse some of the bases and obtain their phred score. To do so look at the ASCII table below.
  ![source of the table](http://www.asciitable.com/index/asciifull.gif "source is www.asciitable.com")
  
> {: .hands_on}

# Quality Control
{:.no_toc}

High Throughput Sequencing machines read thousands or millions of sequences in paralell. As you can imagine, this usually generates large fastq files, with millions of lines. Manually inspecting the quality of each read is out of the question. Specialized software has been developed to provide quality measures for fastq files generated by HTS machines. FastQC is a popular program to generate quality reports on fastq data. It is usually the first thing you should do once you receive a new dataset.

> ### :pencil2: Hands-on: 
>
> 1. Create a new project
> 2. Upload to Galaxy the SRR1030347_2.fastq.interval.fq file provided.

>>    > ### :bulb: Tip: Upload data to Galaxy [[1]](https://galaxyproject.github.io/training-material/topics/introduction/tutorials/galaxy-intro-peaks2genes/tutorial.html) 
>>    >
>>    > * Click on the upload button in the upper left of the interface.

>>    >  ![](https://galaxyproject.github.io/training-material//topics/introduction/images/upload_button.png "source: https://galaxyproject.github.io/training-material//topics/introduction/tutorials/galaxy-intro-peaks2genes/tutorial.html")
>>    > * Press __Choose local file__ and search for your file.
>>    > * As __Type__ select 'fastq'.
>>    > * Press **Start** and wait for the upload to finish. Galaxy will automatically unpack the file.
>>    > * Rename the uploaded dataset to _First dataset_.     
>>    {: .tip}

> 3. **FastQC**:wrench::Run FastQC on the imported file with default parameters
> 4. Inspect the FastQC report on the webpage file, by clicking on the eye (“View data”) on the right of the file name in the history
> {: .hands_on}

## Trimming and Filtering
{:.no_toc}

As you may have noticed in the FastQC report you've just seen, the quality of the reads gets worse towards their end, where there is a higher probability of erroneous bases being called. To avoid problems in subsequent analysis, you should remove regions of poor quality in your read, usually by trimming poor quality bases from the end.

> ### :pencil2: Hands-on: Quality treatment
>
> 1. **Trim Galore!**:wrench::Run Trim Galore on the previously imported data file.
>> a) Is the library paired-end or single-end?: **Single end**
>> b) Reads in FASTQ format: **First Dataset (See the tip below, as you will need to change the type of the data).**
>> c) Adapter sequence to be trimmed: **Automatic detection**, unless you know which adapter sequences were used
>> d) Trim Galore! advanced settings: **Full parameter list**
>> e) Trim low-quality ends from reads: **30**
>> f) Overlap with adapter sequence required to trim a sequence: **5.** The default value "1" can be too stringent.
>> g) Discard reads that became shorter than length N: **20**
>> h) Leave the rest of the settings on default
>
>>    > ### :bulb: Tip: Changing the file type `fastq` to `fastqsanger` of data in your history
>    >
>>    > In order to use the trimmimg tool we need to convert the fastq file previously uploaded to fastqsanger
>    >
>    > * Click on the pencil button displayed in your dataset in the history
>    > * Choose Datatype on the top
>    > * Select ``fastqsanger``
>    > * Press **Save**.     
>    {: .tip}
>    >
>
> 2. **FastQC**:wrench:: Rerun FastQC on the new treated file and compare the results. 
> {: .hands_on}

> ### :question: Questions
>    >
>    > 1. Has the quality of the sequences been improved?
>    >    <details>
>    >    <summary>Click to view answers</summary>
>    >    <ol type="1">
>    >    <li> The per base quality score is better as it is the per base sequence content. The sequence length distribution is worse than before because sequences have different size after the trimming. </li>
>    >    </ol>
>    >    </details>
>    {: .question}
> ### :nut_and_bolt: Comment
>
> - If you send your sequencing to an external facility, they usually do these verifications and filtering for you, and you have “clean” sequences in the end, but it is always better to check. If you need to do this processing yourself, you can also use the *Cutadapt* tool in Galaxy, but you'll also need to know the adaptors that were used in your library preparation (eg. Illumina TruSeq).
> {: .comment}

# Mapping the data
{:.no_toc}

After obtaining millions of short reads, we need to align them to a (sometimes large) reference genome. To achieve this, novel, more efficient, alignment methods had to be developed. One popular method is based on the burrows-wheeler transform and the use of efficient data structures, of which [bwa](http://bio-bwa.sourceforge.net/) and [bowtie](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml) are examples. They enable alignment of millions of reads in a few minutes, even in a laptop.

To store millions of alignments, researchers also had to develop new, more practical formats. The Sequence Alignment/Map (SAM) format is a tabular text file format, where each line contains information for one alignment. SAM files are most often compressed as BAM (Binary SAM) files, to reduce space and allow direct access to alignments in any arbitrary region of the genome. Several tools only work with BAM files.

> ### :pencil2: Hands-on: Alignment to a reference genome
>
> 1. **BWA-MEM**:wrench:: Search in the tool bar on the left the mapper ‘BWA-MEM’. 
>> Settings:
>> a) Will you select a reference genome from your history or use a built-in index?: **Use a genome from history**
>> b) Choose as reference genome the ``E.coli NC_000913.3_MG1655.fasta.``[3](https://www.ncbi.nlm.nih.gov/nuccore/556503834)
>> You may need to upload the file to your history. Please do it as already explained above.
>> c) Single or Paired-end reads: **Single**
>> d) Select fastq dataset: **First Dataset**
>> e) Set read groups information?: **Automatically assign ID**
>> f) Leave the rest of the settings on default

> ### :nut_and_bolt: Comment: Learning about SAM files 
>
> In the SAM format, each alignment line typically represents the linear alignment of a segment. Each line
has 11 mandatory fields.

> ![](https://galaxyproject.github.io/training-material//topics/usegalaxy/images/bam_structure.png) 
> Image from [Introduction to differential gene expression analysis using RNA-seq by Friederike Dundar, Luce Skrabanek, Paul Zumbo](http://chagall.med.cornell.edu/RNASEQcourse/Intro2RNAseq.pdf). To understand more about the information present in SAM files look briefly in [here](https://samtools.github.io/hts-specs/SAMv1.pdf) 
> {: .comment}
>
> 2. **BAM to SAM** :wrench:: Search in the tool bar on the left 'BAM to SAM'
> 3. Select the BAM file obtained with bwa-mem.Click on the eye next to the output file of this tool and inspect briefly the headers and content of the file.
>
>    > ### :question: Questions
>    >
>    > 1. After generating alignments and obtaining a SAM/BAM file, how do I know this step went well?
>    >
>    >    <details>
>    >    <summary>Click to view answers</summary>
>    >    <ol type="1">
>    >    <li> 
>    >    The same way as FastQC generates reports of fastq files to assess quality of raw data, there are programs that generate global reports on the quality of alignments.   
>    >
>    >    The way you check if the alignment step went well depends on your application. Usually, duplication levels higher than 20% are not a good sign (they're a sign of low input DNA and PCR artifacts) but again, depends on what you are sequencing and how much. Similarly, in the case of bacterial sequencing or targeted (eg. exonic) sequencing you expect >95% successful alignment, but if sequencing a full mamallian genome (with many duplicated areas) it may be normal to have as low as 70-80% alignment success. If you have to check the expected “quality” for your application. </li>
>    >    </ol>
>    >    </details>
>    {: .question}
{: .hands_on}

# Visualizing your results
{:.no_toc}

After finishing your analysis, even if you did all the quality checks, and obtained a list of variants, you may want to manually inspect your alignments (you should always manually inspect the regions that are most important for your analysis). For this, there is simple desktop software that you can use to visualize your data, such as [IGV](https://www.broadinstitute.org/igv/).


> ### :pencil2: Hands-on: Visualizing with the IGV browser
>
> 1. **IGV**:wrench::To display the result in IGV open the IGV browser locally on your computer. 
> 2. **IGV**:wrench::Open genome file ``NC_000913.3_MG1655.fasta``
> 2. **Galaxy**:wrench:: Click on the BWA-MEM item on the history panel .
> 3. **Galaxy**:wrench:: Choose in the history on the BWA-MEM results and click on ‘local’ at ‘display with IGV’.
> ![](https://github.com/luisaleitao/training-material/blob/master/topics/introduction/images/display%20with%20IGV.png?raw=true)
> 4. **IGV**:wrench:: The BAM file should be opened in the IGV browser.
> 5. **IGV**:wrench:: Look at the following regions:
>> - NC_000913.3:3846244-3846290 
>> - NC_000913.3:1-1000 and NC_000913.3:4640500-4641652 
>> - NC_000913.3:3759212-3768438 

> ### :nut_and_bolt: Comment: 
Most genomes (particularly mamallian genomes) contain areas of low complexity, composed mostly of repetitive sequences. In the case of short reads, sometimes these align to multiple regions in the genome equally well, making it impossible to know where the fragment came from. Longer reads are needed to overcome these difficulties, or in the absence of these, paired-end data can also be used. **Paired end reads occur when a fragment of DNA is sequenced from two ends and therefore produces two reads.** Some aligners (such as bwa) can use information on paired reads to help disambiguate some alignments. Information on paired reads is also added to the SAM file when proper aligners are used. 
> {: .comment}
>
> ### :question: Questions
>    >
>    > 1. Look at the first region. What do you see?
>    > 2. Now look at the secong region suggested. You can see that some of the reads are coloured. What do you think may happen when assembling an area like this?
>    > 3. Finally, look at the last region. You can see that some reads are white. Try the option 'View as pairs' and analyse the results.
>    >    <details>
>    >    <summary>Click to view answers</summary>
>    >    <ol type="1">
>    >    <li> 
>    >    1.You can see that this region has an SNP (a C instead of an A in the genome).
>    >
>    >    2.The coloured reads that you see in this case represent reads in which the insert size is larger than expected. You can see it at the beginning and at the end of the chromossome. This happens due to the chromossome of the E.coli being circular, therefore when sequencing from both ends of the fragment of DNA, the pair that corresponds to the the one at the beginning of the genome is at the end.
>    >
>    >    3.The reads are white because they have a mapping quality equal to zero or, as happens in this case, the read also maps to another location with equally good placement. When you view them as pairs, the program can gather information from a read that the program is sure in their location and at the same time happens to be the pair for a white read. So, when viewing as pairs, IGV uses that information and, based on the read that he is confident in the location and knowing that it also pairs to a white one, he can be sure now that the white read belongs there.</li>
>    >    </ol>
>    >    </details>
>    {: .question}
 
> {: .hands_on}
# Constructing your workflow

As you learnt in [Galaxy 101 tutorial](https://galaxyproject.github.io/training-material/topics/introduction/tutorials/galaxy-intro-101/tutorial.html#convert-your-analysis-history-into-a-workflow) you can create a workflow that runs all the steps at once, saving you a lot of time. We're are also going to create one for this analysis.
>
> ### :pencil2: Hands-on: Extract workflow
>
> 1. **Clean up** your history. If you had any failed jobs (red), please remove those datasets from your history by clicking on the `x` button. This will make the creation of a workflow easier.
> 2. Go to the history **Options menu** (gear symbol) and select the ``Extract Workflow`` option.
![](https://github.com/luisaleitao/training-material/blob/master/topics/introduction/images/history_menu_extract_workflow.png?raw=true)
>The center pane will change as shown below and you will be able to choose which steps to include/exclude and how to name the newly created workflow.
![](https://github.com/luisaleitao/training-material/blob/master/topics/introduction/images/Screenshot%20from%202017-08-17%2017-38-53.png?raw=true)
>
> 3. **Uncheck **any steps that shouldn’t be included in the workflow (if any), and **rename** the workflow to ``NGS Analysis``.
> 4. Click on the **Create Workflow** button near the top.
You will get a message that the workflow was created. But where did it go?
> 5. Click on **Workflow** in the top menu of Galaxy. Here you have a list of all your workflows. Your newly created workflow should be listed at the top:
{: .hands_on}
## The workflow editor

We can examine the workflow in Galaxy’s workflow editor. Here you can view/change the parameter settings of each step, add and remove tools, and connect an output from one tool to the input of another, all in an easy and graphical manner. You can also use this editor to build workflows from scratch.

> ### :pencil2: Hands-on: Edit workflow
>
> 1. Click on the triangle to the right of your workflow name.
![](https://github.com/luisaleitao/training-material/blob/master/topics/introduction/images/workflow_edit.png?raw=true)
> 2. Select **Edit** to launch the workflow editor. You should see something like this:
![](https://github.com/luisaleitao/training-material/blob/master/topics/introduction/images/example_workflow.png?raw=true)
>When you click on a component, you will get a view of all the parameter settings for that tool on the right-hand side of your screen.
>
> 3. **Click the asterisk** next to ``output1`` in the ``bam_output(bam)``. Now, when we run the workflow, we will only see the final two outputs, the BAM and the corresponding SAM file. Once you have done this, you will notice that the **minimap** at the bottom-right corner will have orange boxes representing a tool with an output that will be shown.
![](https://github.com/luisaleitao/training-material/blob/master/topics/introduction/images/101_31.png?raw=true)
>If you didn’t specify a name for the input files at the beginning they will be labeled ``Input Dataset``. 
> 4. **Save your workflow** (important!) by clicking on the gear icon at the top right of the screen, and selecting Save.
![](https://galaxyproject.github.io/training-material/topics/introduction/images/workflow_editor_save.png)
> 5. **Return **to the analysis view by clicking on ``Analyze Data`` at the top menu bar.
{: .hands_on}

> ### :nut_and_bolt: Comment: 
>
> We could **validate** our newly built workflow by running it on the same input datasets used before in this tutorial to  make sure we do obtain the same results. 
> {: .comment}

